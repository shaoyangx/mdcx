#!/usr/bin/env python3
import json
import re
import time
import urllib.parse

import urllib3
from lxml import etree

from models.base.web import curl_html
from models.config import config
from models.signals import signal


urllib3.disable_warnings()  # yapf: disable

def get_title(html):
    result = html.xpath('//div[@class="video-description-panel video-description-panel-hover no-select"]/div[2]/text()')[0].strip()
    # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼å»æ‰ä¸­æ‹¬å·åŠå…¶å†…å®¹
    return result

def get_outline(html):
    result = html.xpath('//div[@class="video-description-panel video-description-panel-hover no-select"]/div[3]/text()')[0].strip()
    result = str(result)
    return result

def get_tag(html):
    result = html.xpath('//div[@style="margin-bottom: 18px; font-weight: normal"]/a/text()')
    # æ¸…ç†Tagä¸­çš„æ ‡ç­¾
    result = [tag for tag in result if not re.match(r'^(1080(P)*)$', tag, re.IGNORECASE)] 
    return ",".join(result) if result else ""

def retry_request(html_info, log_info, web_info):
    title = get_title(html_info)  # è·å–æ ‡é¢˜
    if not title:
        debug_info = "æ•°æ®è·å–å¤±è´¥: æœªè·å–åˆ°titleï¼"
        log_info += web_info + debug_info
        raise Exception(debug_info)
    outline = get_outline(html_info)
    tag = get_tag(html_info)
    return title, outline, tag, log_info


def get_real_url(html, number):
    """
    ä»æœç´¢ç»“æœé¡µé¢ä¸­è·å–æœ€åŒ¹é…çš„è¯¦æƒ…é¡µURL
    :param html: HTMLè§£æåçš„å…ƒç´ æ ‘
    :param number: è¦åŒ¹é…çš„ç•ªå·
    :return: åŒ¹é…ç»“æœçŠ¶æ€ã€åŒ¹é…çš„ç•ªå·ã€æ ‡é¢˜å’ŒURL
    """
    item_list = html.xpath('//div[@class="col-xs-6 col-sm-4 col-md-2 search-doujin-videos hidden-xs hover-lighter multiple-link-wrapper"]')

    for item in item_list:
        detail_url = item.xpath("./a/@href")[0].strip()
        #è·å–æœç´¢ç»“æœé¡µ
        if detail_url:
            result, html = curl_html(detail_url)
            if not result:
                debug_info = f"ç½‘ç»œè¯·æ±‚é”™è¯¯: {html} "
                log_info += debug_info
                raise Exception(debug_info)
            html = etree.fromstring(html, etree.HTMLParser())
        raw_title = html.xpath('//h3[@id="shareBtn-title"]/text()')[0].strip()
        title = re.sub(r"[\W_]", "", raw_title).upper()
        number = re.sub(r"[\W_]", "", number).upper()
        # æ¯”è¾ƒæ ‡é¢˜ä¸ç•ªå·æ˜¯å¦åŒ¹é…
        if number.upper() in title:
            return detail_url,html
    return ""



def main(number,appoint_url="",log_info="",req_web="",language="zh_cn"):
    """
    ä¸»å‡½æ•°ï¼Œè·å–å½±ç‰‡ä¿¡æ¯
    :param number: ç•ªå·
    :param appoint_url: æŒ‡å®šçš„URL
    :param log_info: æ—¥å¿—ä¿¡æ¯
    :param req_web: è¯·æ±‚ç½‘ç«™ä¿¡æ¯
    :param language: è¯­è¨€
    :return: JSONæ ¼å¼çš„å½±ç‰‡ä¿¡æ¯
    """
    start_time = time.time()
    website_name = "hanime1"
    req_web += "-> %s" % website_name
    title = ""
    web_info = "\n       "
    log_info += " \n    ğŸŒ hanime1"
    debug_info = ""
    real_url = appoint_url
    hanime1_url = "https://hanime1.me"
    number2 = re.sub('#', ' ', number)
    try: # æ•è·ä¸»åŠ¨æŠ›å‡ºçš„å¼‚å¸¸
        if not real_url:
            # é€šè¿‡æœç´¢è·å–real_url
            url_search = hanime1_url + f"/search?query={number2}"
            debug_info = f"æœç´¢åœ°å€: {url_search} "
            log_info += web_info + debug_info

            result, html_search = curl_html(url_search)
            if not result:
                debug_info = f"ç½‘ç»œè¯·æ±‚é”™è¯¯: {html_search} "
                log_info += web_info + debug_info
                raise Exception(debug_info)
            html = etree.fromstring(html_search, etree.HTMLParser())
            #æ•è·åˆ—è¡¨
            real_url = html.xpath('//div[@class="col-xs-6 col-sm-4 col-md-2 search-doujin-videos hidden-xs hover-lighter multiple-link-wrapper"]/a[@href]/@href')
            if not real_url:
                debug_info = "æœç´¢ç»“æœ: æœªåŒ¹é…åˆ°ç•ªå·ï¼"
                log_info += web_info + debug_info
                raise Exception(debug_info)

        if real_url:
            real_url,html_info = get_real_url(html, number)
            # æœç´¢ç»“æœé¡µé¢æœ‰æ¡ç›®ï¼Œä½†æ— æ³•åŒ¹é…åˆ°ç•ªå·
            if not real_url:
                debug_info = "æœç´¢ç»“æœ: æœªåŒ¹é…åˆ°ç•ªå·ï¼2"
                log_info += web_info + debug_info
                raise Exception(debug_info)
            else:
                real_url = urllib.parse.urljoin(hanime1_url, real_url) if real_url.startswith("/") else real_url

            debug_info = f"ç•ªå·åœ°å€: {real_url} "
            log_info += web_info + debug_info
            title, outline, tag, log_info = retry_request(
                html_info, log_info, web_info
            )
            try:
                dic = {
                    "number": number,
                    "title": title,
                    "originaltitle": title,
                    "actor": "",
                    "outline": outline,
                    "originalplot": outline,
                    "tag": tag,
                    "release": "",
                    "year": "",
                    "runtime": "",
                    "score": "",
                    "series": "",
                    "director": "",
                    "studio": "",
                    "publisher": "",
                    "source": "hanime1",
                    "actor_photo": "",
                    "cover": "",
                    "poster": "",
                    "extrafanart": "",
                    "trailer": "",
                    "image_download": "",
                    "image_cut": "",
                    "log_info": log_info,
                    "error_info": "",
                    "req_web": req_web + f"({round((time.time() - start_time), )}s) ",
                    "mosaic": "",
                    "website": real_url,
                    "wanted": "",
                }
                debug_info = "æ•°æ®è·å–æˆåŠŸï¼"
                log_info += web_info + debug_info
                dic["log_info"] = log_info
            except Exception as e:
                debug_info = f"æ•°æ®ç”Ÿæˆå‡ºé”™: {str(e)}"
                log_info += web_info + debug_info
                raise Exception(debug_info)
    except Exception as e:
        # print(traceback.format_exc())
        debug_info = str(e)
        dic = {
            "title": "",
            "website": "",
            "log_info": log_info,
            "error_info": debug_info,
            "req_web": req_web + f"({round((time.time() - start_time), )}s) ",
        }
    dic = {website_name: {"zh_cn": dic, "zh_tw": dic, "jp": dic}}
    js = json.dumps(
        dic,
        ensure_ascii=False,
        sort_keys=False,
        indent=4,
        separators=(",", ": "),
    )  # .encode('UTF-8')
    return js

if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    #print(main("OVAã‚¹ã‚±ãƒ™ã‚¨ãƒ«ãƒ•æ¢è¨ªè¨˜"))
    print(main("OVAã‚¹ã‚±ãƒ™ã‚¨ãƒ«ãƒ•æ¢è¨ªè¨˜ #2"))
    # æµ‹è¯•æœç´¢åŠŸèƒ½
    # results = search("å·¨ä¹³", 1)
    # print(f"æœç´¢ç»“æœæ•°é‡: {len(results)}")
    # if results:
    #     print(f"ç¬¬ä¸€ä¸ªç»“æœ: {results[0]}")
